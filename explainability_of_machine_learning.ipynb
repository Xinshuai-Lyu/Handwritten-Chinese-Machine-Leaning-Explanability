{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "armed-conducting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.text import Text\n",
    "from matplotlib.widgets import Button\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-hostel",
   "metadata": {},
   "source": [
    "### Data preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-feeling",
   "metadata": {},
   "source": [
    "#### models coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "active-identity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_model(input_size):\n",
    "    input1 = keras.layers.Input(shape=(input_size*input_size))\n",
    "    output = keras.layers.Dense(1, activation='sigmoid')(input1)\n",
    "    linear_model = keras.Model(inputs=[input1], outputs=[output])\n",
    "    linear_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return linear_model\n",
    "input_sizes = [8, 16, 32, 64, 128]\n",
    "checkpoint_paths = [\n",
    "    \"xinshuai_models/linearmodel/8\\\\0243.ckpt\",\n",
    "    \"xinshuai_models/linearmodel/16\\\\0171.ckpt\",\n",
    "    \"xinshuai_models/linearmodel/32\\\\0062.ckpt\",\n",
    "    \"xinshuai_models/linearmodel/64\\\\0054.ckpt\",\n",
    "    \"xinshuai_models/linearmodel/128\\\\0026.ckpt\"\n",
    "]\n",
    "def get_coefficients(i):\n",
    "    input_size = input_sizes[i]\n",
    "    checkpoint_path = checkpoint_paths[i]\n",
    "    linear_model = get_linear_model(input_size)\n",
    "    linear_model.load_weights(checkpoint_path)\n",
    "    coefficients = list(np.reshape(linear_model.variables[0].numpy(), input_size*input_size))\n",
    "    return coefficients\n",
    "# 8x8\n",
    "_8 = get_coefficients(0)\n",
    "# 16x16\n",
    "_16 = get_coefficients(1)\n",
    "# 32x32\n",
    "_32 = get_coefficients(2)\n",
    "# 64x64\n",
    "_64 = get_coefficients(3)\n",
    "# 128x128\n",
    "_128 = get_coefficients(4)\n",
    "\n",
    "models_coefficients = [_8, _16, _32, _64, _128]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-warner",
   "metadata": {},
   "source": [
    "#### models input sizes and accuracy results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "exterior-carroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"accuracy_in_different_input_size\")\n",
    "input_sizes = df[\"input_sizes\"].to_list()\n",
    "accuracys = df[\"accuracys\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-sampling",
   "metadata": {},
   "source": [
    "#### 火(Fire) and 水(water) images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "floral-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base path\n",
    "train_base_path = os.path.join(os.curdir, \"Train\")\n",
    "\n",
    "# 火(Fire) path\n",
    "fire = \"火\"\n",
    "fire_base_path = os.path.join(train_base_path, fire)\n",
    "\n",
    "# 水(Water) path\n",
    "water = \"水\"\n",
    "water_base_path = os.path.join(train_base_path, water)\n",
    "\n",
    "fires = os.listdir(fire_base_path)\n",
    "waters = os.listdir(water_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "instrumental-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_fire_water():\n",
    "    fire_index = int(np.random.random() * len(fires))\n",
    "    water_index = int(np.random.random() * len(waters))\n",
    "    fire_image = Image.open(os.path.join(fire_base_path, fires[fire_index]))\n",
    "    water_image = Image.open(os.path.join(water_base_path, waters[water_index]))\n",
    "    # fire and water images\n",
    "    fire_image = fire_image.convert('L')\n",
    "    water_image = water_image.convert('L')\n",
    "    return fire_image, water_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-vulnerability",
   "metadata": {},
   "source": [
    "#### models top N influential power pixels (by coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "employed-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Nth_influential_power_pixel_coefficient(model_coefficients, N):\n",
    "    top_N = model_coefficients[:N]\n",
    "    top_N.sort()\n",
    "    top_N = list(top_N)\n",
    "    i = N\n",
    "    while i < len(model_coefficients):\n",
    "        top_N.append(model_coefficients[i])\n",
    "        top_N.sort()\n",
    "        top_N.pop(0)\n",
    "        i += 1\n",
    "    return top_N[0]\n",
    "def get_top_N_influential_power_pixels(which_model, N):\n",
    "    model_coefficients = models_coefficients[which_model]\n",
    "    model_input_size = input_sizes[which_model]\n",
    "    the_Nth_influential_power_pixel_coefficient = get_Nth_influential_power_pixel_coefficient(model_coefficients, N)\n",
    "    model_pixels_y_position = []\n",
    "    model_pixels_x_position = []\n",
    "    for i, model_coefficient in enumerate(model_coefficients):\n",
    "        if model_coefficient >= the_Nth_influential_power_pixel_coefficient:\n",
    "            # \"model_input_size - i // model_input_size\" because the lower y in list means higher position in image\n",
    "            model_pixels_y_position.append(model_input_size - i // model_input_size)\n",
    "            model_pixels_x_position.append(i % model_input_size)\n",
    "    return model_pixels_x_position, model_pixels_y_position, model_input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ambient-prior",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = np.argmax(accuracys)\n",
    "N = 20\n",
    "best_model_x, best_model_y, best_model_input_size = get_top_N_influential_power_pixels(best_model, N)\n",
    "#*0.05 because 64 pixels are small for I wanna show the most significant pixels\n",
    "_8model_x, _8model_y, _8model_input_size = get_top_N_influential_power_pixels(0, int(8*8*0.05)) \n",
    "_16model_x, _16model_y, _16model_input_size = get_top_N_influential_power_pixels(1, int(16*16*0.05)) # same reason\n",
    "_32model_x, _32model_y, _32model_input_size = get_top_N_influential_power_pixels(2, N)\n",
    "_64model_x, _64model_y, _64model_input_size = get_top_N_influential_power_pixels(3, N)\n",
    "_128model_x, _128model_y, _128model_input_size = get_top_N_influential_power_pixels(4, N)\n",
    "\n",
    "xs = [_8model_x, _16model_x, _32model_x, _64model_x, _128model_x]\n",
    "ys = [_8model_y, _16model_y, _32model_y, _64model_y, _128model_y]\n",
    "model_input_sizes = [_8model_input_size, _16model_input_size, _32model_input_size, \n",
    "                     _64model_input_size, _128model_input_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-chase",
   "metadata": {},
   "source": [
    "### Data Interactive Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-refund",
   "metadata": {},
   "source": [
    "#### Style graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "stunning-sullivan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_axes(axes, is_image=False):\n",
    "    for ax in axes:\n",
    "        ax.tick_params(labelsize=\"xx-small\", pad=-2)\n",
    "        ax.tick_params(top=False, left=False, bottom=False, right=False)\n",
    "        if is_image:\n",
    "            ax.tick_params(labeltop=False, labelleft=False, labelbottom=False, labelright=False)\n",
    "            ax.axis('off')\n",
    "def set_main_title(text):\n",
    "    plt.suptitle(text, size=\"x-small\", weight=\"bold\")\n",
    "def set_sub_title(ax, text):\n",
    "    ax.set_title(text, size=\"xx-small\", pad=2, weight=\"bold\")\n",
    "def set_label(ax, text, flag=\"x\"):\n",
    "    if flag == \"x\":\n",
    "        ax.set_xlabel(text, size=\"xx-small\")\n",
    "    else:\n",
    "        ax.set_ylabel(text, size=\"xx-small\")\n",
    "def text_markers(ax, model_x, model_y, top_N_influential_power_pixels):\n",
    "    i = 0\n",
    "    for coefficient in top_N_influential_power_pixels:\n",
    "        ax.text(model_x[i],\n",
    "                 model_y[i], \n",
    "                 str(coefficient), \n",
    "                 size=\"xx-small\")\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-peninsula",
   "metadata": {},
   "source": [
    "#### Contain graphs in Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "biblical-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid():\n",
    "    fig = plt.figure()\n",
    "    gs0 = gridspec.GridSpec(1, 2, figure=fig)\n",
    "    gs00 = gridspec.GridSpecFromSubplotSpec(5, 6, subplot_spec=gs0[0])\n",
    "    ax1 = fig.add_subplot(gs00[0:1, 0:3])\n",
    "    ax2 = fig.add_subplot(gs00[0:1, 3:6])\n",
    "    ax3 = fig.add_subplot(gs00[1:3, :])\n",
    "    ax4 = fig.add_subplot(gs00[3:5, :])\n",
    "    gs01 = gridspec.GridSpecFromSubplotSpec(5, 6, subplot_spec=gs0[1])\n",
    "    ax_button = fig.add_subplot(gs01[0:1, 1:5])\n",
    "    ax5 = fig.add_subplot(gs01[1:3, :])\n",
    "    ax6 = fig.add_subplot(gs01[3:5, :])\n",
    "    return fig, ax1, ax2, ax3, ax4, ax_button, ax5, ax6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-difficulty",
   "metadata": {},
   "source": [
    "#### Paint graphs and Make graphs interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "legendary-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_image, water_image = get_random_fire_water()\n",
    "resized_fires = [fire_image.resize((8,8)), fire_image.resize((16,16)),\n",
    "             fire_image.resize((32,32)), fire_image.resize((64,64)),\n",
    "             fire_image.resize((128,128))]\n",
    "resized_waters = [water_image.resize((8,8)), water_image.resize((16,16)),\n",
    "                 water_image.resize((32,32)), water_image.resize((64,64)),\n",
    "                 water_image.resize((128,128))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "technological-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_ax1_ax2(fire_image, water_image):\n",
    "    ax1.figure.canvas.draw_idle()\n",
    "    ax1.cla()\n",
    "    ax2.figure.canvas.draw_idle()\n",
    "    ax2.cla()\n",
    "    set_sub_title(ax1, \"Chinese Handwritten Fire\")\n",
    "    set_sub_title(ax2, \"Water\")\n",
    "    ax1.imshow(fire_image, cmap=\"gray\")\n",
    "    ax2.imshow(water_image, cmap=\"gray\")\n",
    "    format_axes([ax1, ax2], is_image=True)\n",
    "def draw_ax3(model_index=-1):\n",
    "    colors = ['r', 'r', 'r', 'r', 'r']\n",
    "    ax3.figure.canvas.draw_idle()\n",
    "    ax3.cla()\n",
    "    colors[model_index] = 'green'\n",
    "    set_sub_title(ax3, \"Accuracy as function of input size in linear model\")\n",
    "    set_label(ax3, \"input size\", \"x\")\n",
    "    set_label(ax3, \"accuracy\", \"y\")\n",
    "    ax3.scatter(input_sizes, accuracys, marker=\"8\", picker=True, \n",
    "                    c=['r', 'r', 'r', 'r', 'r'])\n",
    "    ax3.legend(labels=[\"UNSELECTED\"], labelcolor=[\"red\"],\n",
    "                    loc=\"lower right\", title=\"STATUS\", fontsize=\"xx-small\", title_fontsize=\"xx-small\")\n",
    "    ax3.scatter(input_sizes, accuracys, marker=\"8\", picker=True, \n",
    "                    c=colors)\n",
    "    ax3.plot(input_sizes, accuracys)\n",
    "    format_axes([ax3])\n",
    "def draw_ax4(model_index):\n",
    "    ax4.cla()\n",
    "    ax4.figure.canvas.draw_idle()\n",
    "    model_x = xs[model_index]\n",
    "    model_y = ys[model_index]\n",
    "    model_input_size = model_input_sizes[model_index]\n",
    "    set_sub_title(ax4, f\"The pixels model({model_input_size}x{model_input_size}) focuses on\")\n",
    "    ax4.set_xlim(0, model_input_size)\n",
    "    ax4.set_ylim(0, model_input_size)\n",
    "    ax4.scatter(model_x, model_y, marker=\"8\", color=\"red\")\n",
    "    set_label(ax4, \"x\", \"x\")\n",
    "    set_label(ax4, \"y\", \"y\")\n",
    "    format_axes([ax4])\n",
    "def draw_image(ax, image, model_index):\n",
    "    image_input_size = model_input_sizes[model_index]\n",
    "    image = np.array(image)\n",
    "    image = np.reshape(image, image_input_size*image_input_size)\n",
    "    model_pixels_y_position = []\n",
    "    model_pixels_x_position = []\n",
    "    for i, pixel in enumerate(image):\n",
    "        # < 255 can ignore white pixels\n",
    "        if pixel < 255:\n",
    "            model_pixels_y_position.append(image_input_size - i // image_input_size)\n",
    "            model_pixels_x_position.append(i % image_input_size)\n",
    "    ax.scatter(model_pixels_x_position, model_pixels_y_position, s=1, color=\"black\")\n",
    "def draw_ax5_ax6(model_index):\n",
    "    ax5.cla()\n",
    "    ax5.figure.canvas.draw_idle()\n",
    "    ax6.cla()\n",
    "    ax6.figure.canvas.draw_idle()\n",
    "    model_x = xs[model_index]\n",
    "    model_y = ys[model_index]\n",
    "    model_input_size = model_input_sizes[model_index]\n",
    "    ax5.scatter(model_x, model_y, marker=\"8\", color=\"red\")\n",
    "    ax5.set_xlim(0, model_input_size)\n",
    "    ax5.set_ylim(0, model_input_size)\n",
    "    draw_image(ax5, resized_fires[model_index], model_index)\n",
    "\n",
    "    ax6.scatter(model_x, model_y, marker=\"8\", color=\"red\")\n",
    "    ax6.set_xlim(0, model_input_size)\n",
    "    ax6.set_ylim(0, model_input_size)\n",
    "    draw_image(ax6, resized_waters[model_index], model_index)\n",
    "    \n",
    "    set_sub_title(ax5, f\"The pixels model({model_input_size}x{model_input_size}) focuses on\")\n",
    "    set_label(ax5, \"x\", \"x\")\n",
    "    set_label(ax5, \"y\", \"y\")\n",
    "    set_label(ax6, \"x\", \"x\")\n",
    "    set_label(ax6, \"y\", \"y\")\n",
    "    \n",
    "    format_axes([ax5, ax6])\n",
    "    \n",
    "selected_model_index = best_model\n",
    "def button_pressed(event):\n",
    "    fire_image, water_image = get_random_fire_water()\n",
    "    global resized_fires, resized_waters\n",
    "    resized_fires = [fire_image.resize((8,8)), fire_image.resize((16,16)),\n",
    "                 fire_image.resize((32,32)), fire_image.resize((64,64)),\n",
    "                 fire_image.resize((128,128))]\n",
    "    resized_waters = [water_image.resize((8,8)), water_image.resize((16,16)),\n",
    "                     water_image.resize((32,32)), water_image.resize((64,64)),\n",
    "                     water_image.resize((128,128))]\n",
    "    draw_ax1_ax2(fire_image, water_image)\n",
    "    draw_ax5_ax6(selected_model_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "utility-basin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x28bd8311a00>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax1, ax2, ax3, ax4, ax_button, ax5, ax6 = create_grid()\n",
    "\n",
    "main_title = '''How machine learning model distinguishes between Chinese handwritten Fire and Water\n",
    "in different sizes\n",
    "'''\n",
    "set_main_title(main_title)\n",
    "\n",
    "draw_ax1_ax2(fire_image, water_image)\n",
    "\n",
    "draw_ax3(best_model)\n",
    "ax3_original_facecolor = ax3.get_facecolor()\n",
    "\n",
    "draw_ax4(best_model)\n",
    "pos_ax4 = ax4.get_position() \n",
    "ax4.set_position([pos_ax4.x0, pos_ax4.y0 - 0.05,  pos_ax4.width, pos_ax4.height] )\n",
    "\n",
    "myButton = Button(ax_button, 'Use other Fire/Water images', color='#34e5eb', hovercolor='#348feb')\n",
    "myButton.label.set_fontsize('x-small')\n",
    "myButton.on_clicked(button_pressed)\n",
    "\n",
    "draw_ax5_ax6(best_model)\n",
    "\n",
    "def onpick(event):\n",
    "    global selected_model_index\n",
    "    ind = event.ind\n",
    "    model_index = ind[0]\n",
    "    draw_ax3(model_index)\n",
    "    draw_ax4(model_index)\n",
    "    draw_ax5_ax6(model_index)\n",
    "    selected_model_index = model_index\n",
    "fig.canvas.mpl_connect('pick_event', onpick)\n",
    "plt.show()\n",
    "plt.ion()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
